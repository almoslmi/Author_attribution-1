{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import svm, model_selection, tree, preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import codecs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "le=preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "def author_identify():\n",
    "    \n",
    "    \n",
    "\n",
    "    start=chr(0x900)                    # 0x900 is the unicode point of first character of hindi alphabet\n",
    "    end=chr(0x97F)                      # 0x900 is the unicode point of last character of hindi alphabet\n",
    "\n",
    "\n",
    "    vectorizer=CountVectorizer(token_pattern=\"[\"+start+\"-\"+end+\"]+\",min_df = 0)\n",
    "\n",
    "    path='/mnt/A042994142991CDA/Hindi_train/'           #directory consisting a folder for each author\n",
    "    authors=os.listdir(path);\n",
    "    authors=authors[:5]\n",
    "\n",
    "    \n",
    "    files=[]\n",
    "    document=[]\n",
    "    #getting the list of files\n",
    "    for author in authors:\n",
    "        newpath=path+author+'/'\n",
    "        x=os.listdir(newpath)\n",
    "        for every_file in x:\n",
    "            full_path=newpath+every_file\n",
    "            files=files+[full_path]\n",
    "\n",
    "   \n",
    "    for file in files:\n",
    "        \n",
    "        doc = codecs.open(file, \"r\", encoding='utf-16')\n",
    "        doc = doc.read()\n",
    "        document=document+[doc]\n",
    "\n",
    "    #transforming data into feature vector\n",
    "    X=vectorizer.fit_transform(document)\n",
    "    train_data_X=pd.DataFrame(data=X.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    Y=[]\n",
    "    for author in authors:\n",
    "        newpath=path+author+'/'\n",
    "        x=os.listdir(newpath)\n",
    "        for every_file in x:\n",
    "            Y=Y+[author]\n",
    "\n",
    "    train_data_Y=le.fit_transform(Y)\n",
    "\n",
    "    model=RandomForestClassifier()\n",
    "    parameters=[{'n_estimators':[1000],'max_depth':[7]}]\n",
    "    clf=GridSearchCV(model,param_grid=parameters,cv=10,n_jobs=2)\n",
    "    clf.fit(train_data_X,train_data_Y)\n",
    "    print(clf.best_score_)\n",
    "    \n",
    "      \n",
    "\n",
    "\n",
    "author_identify()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
